import streamlit as st
import openai
import google.generativeai as genai
from anthropic import Anthropic
from datetime import datetime
import pandas as pd
import json
import pathlib
import plotly.express as px
from typing import Dict, List, Optional
from dataclasses import dataclass

# Initialize API keys from Streamlit secrets
openai.api_key = st.secrets["chatgpt"]
genai.configure(api_key=st.secrets["gemini"])
anthropic = Anthropic(api_key=st.secrets["claude"])


#ì±—-ì œ-í´ ìˆœì„œ ì˜¤ì™€ì—´
model_zoo = ['gpt-4o',
             'gemini-1.5-pro-exp-0827',
             'claude-3-5-haiku-20241022']

# Gemini model configuration
gemini_model = genai.GenerativeModel(model_zoo[1])


# CSS 


# Custom CSS for modern design
st.markdown("""
<style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');

    /* ì „ì²´ í°íŠ¸ ë° ìƒ‰ìƒ ìŠ¤íƒ€ì¼ */
    [data-testid="stAppViewContainer"] {
        font-family: 'Pretendard', sans-serif;
        background-color: #f8fafc;
    }

    /* í—¤ë” ìŠ¤íƒ€ì¼ë§ */
    h1, h2, h3, h4, h5, h6 {
        font-family: 'Pretendard', sans-serif;
        font-weight: 700;
        color: #1e293b;
    }

    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .stCard {
        border-radius: 15px;
        box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1), 0 2px 4px -1px rgba(0,0,0,0.06);
        padding: 1rem;
        background-color: white;
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ */
    .stButton > button {
        background-color: #3b82f6;
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.2s ease;
    }
    .stButton > button:hover {
        background-color: #2563eb;
        transform: translateY(-1px);
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ë§ */
    [data-testid="stSidebar"] {
        background-color: white;
        border-right: 1px solid #e2e8f0;
        padding: 2rem 1rem;
    }
    [data-testid="stSidebar"] .stMarkdown {
        padding: 0.5rem 0;
    }

    /* ì…€ë ‰íŠ¸ë°•ìŠ¤ ìŠ¤íƒ€ì¼ë§ */
    .stSelectbox > div > div {
        background-color: white;
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        padding: 0.5rem;
    }

    /* ê²°ê³¼ ì¹´ë“œ ìŠ¤íƒ€ì¼ë§ */
    .result-card {
        background-color: white;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    /* ëª¨ë¸ íƒœê·¸ ìŠ¤íƒ€ì¼ë§ */
    .model-tag {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    .gpt-tag { background-color: #10b981; color: white; }
    .gemini-tag { background-color: #6366f1; color: white; }
    .claude-tag { background-color: #8b5cf6; color: white; }

    /* í‰ê°€ ê²°ê³¼ ìŠ¤íƒ€ì¼ë§ */
    .evaluation-score {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1e293b;
    }
    .evaluation-reason {
        color: #64748b;
        font-size: 0.875rem;
        line-height: 1.5;
        margin-top: 0.5rem;
    }

    /* í…ìŠ¤íŠ¸ ì˜ì—­ ìŠ¤íƒ€ì¼ë§ */
    .stTextArea > div > textarea {
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        padding: 1rem;
        font-family: 'Pretendard', sans-serif;
    }

    /* ë¡œë”© ìŠ¤í”¼ë„ˆ ìŠ¤íƒ€ì¼ë§ */
    .stSpinner > div {
        border-color: #3b82f6;
    }

    /* íƒ­ ìŠ¤íƒ€ì¼ë§ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: white;
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        color: #1e293b;
        font-weight: 500;
    }
    .stTabs [aria-selected="true"] {
        background-color: #3b82f6;
        color: white;
        border: none;
    }

    /* ê²½ê³ /ì„±ê³µ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ */
    .stAlert {
        border-radius: 8px;
        padding: 1rem;
    }
    .stSuccess {
        background-color: #ecfdf5;
        color: #065f46;
    }
    .stError {
        background-color: #fef2f2;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)








# MBTI ê·¸ë£¹ ìƒìˆ˜ ì •ì˜
MBTI_GROUPS = {
    "ë¶„ì„ê°€í˜•": ["INTJ", "INTP", "ENTJ", "ENTP"],
    "ì™¸êµê´€í˜•": ["INFJ", "INFP", "ENFJ", "ENFP"],
    "ê´€ë¦¬ìí˜•": ["ISTJ", "ISFJ", "ESTJ", "ESFJ"],
    "íƒí—˜ê°€í˜•": ["ISTP", "ISFP", "ESTP", "ESFP"]
}

# ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜ ìˆ˜ì •
def load_docs() -> Dict[str, Dict[str, str]]:
    docs_path = pathlib.Path("docs")
    docs = {
        "region": {},
        "generation": {},
        "mbti": {}
    }
    
    # ì§€ì—­ ë¬¸ì„œ ë¡œë“œ
    region_path = docs_path / "regions"
    if region_path.exists():
        for file in region_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["region"][file.stem] = f.read()
    
    # ì„¸ëŒ€ ë¬¸ì„œ ë¡œë“œ
    generation_path = docs_path / "generations"
    if generation_path.exists():
        for file in generation_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["generation"][file.stem] = f.read()
    
    # MBTI ë¬¸ì„œ ë¡œë“œ (ë‹¨ì¼ íŒŒì¼)
    mbti_file = docs_path / "mbti" / "mbti_all.txt"
    if mbti_file.exists():
        with open(mbti_file, "r", encoding="utf-8") as f:
            content = f.read()
            # ê° MBTI ì„¹ì…˜ íŒŒì‹±
            for group in MBTI_GROUPS.keys():
                group_start = content.find(f"[{group}]")
                next_group_start = len(content)
                for other_group in MBTI_GROUPS.keys():
                    if other_group != group:
                        pos = content.find(f"[{other_group}]")
                        if pos > group_start and pos < next_group_start:
                            next_group_start = pos
                
                group_content = content[group_start:next_group_start].strip()
                for mbti in MBTI_GROUPS[group]:
                    mbti_start = group_content.find(mbti)
                    next_mbti_start = len(group_content)
                    for other_mbti in MBTI_GROUPS[group]:
                        if other_mbti != mbti:
                            pos = group_content.find(other_mbti)
                            if pos > mbti_start and pos < next_mbti_start:
                                next_mbti_start = pos
                    
                    mbti_content = group_content[mbti_start:next_mbti_start].strip()
                    docs["mbti"][mbti.lower()] = mbti_content
    
    return docs


@dataclass
class ScoringConfig:
    """í‰ê°€ ì‹œìŠ¤í…œ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    prompt: str
    criteria: List[str]
    min_score: int = 0
    max_score: int = 100
    
    def to_dict(self) -> dict:
        return {
            "prompt": self.prompt,
            "criteria": self.criteria,
            "min_score": self.min_score,
            "max_score": self.max_score
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'ScoringConfig':
        return cls(**data)

class AdCopyEvaluator:
    """ê´‘ê³  ì¹´í”¼ í‰ê°€ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, scoring_config: ScoringConfig):
        self.scoring_config = scoring_config
        self.results_cache = {}
    
    def evaluate(self, copy: str, model_name: str) -> Dict:
        """í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ íŒŒì‹±"""
        try:
            # Check cache
            cache_key = f"{copy}_{model_name}"
            if cache_key in self.results_cache:
                return self.results_cache[cache_key]
            
            # Construct evaluation prompt
            evaluation_prompt = f"""
{self.scoring_config.prompt}

í‰ê°€ ëŒ€ìƒ ì¹´í”¼: {copy}

í‰ê°€ ê¸°ì¤€:
{chr(10).join(f'- {criterion}' for criterion in self.scoring_config.criteria)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì ìˆ˜: [0-100 ì‚¬ì´ì˜ ìˆ«ì]
ì´ìœ : [í‰ê°€ ê·¼ê±°]
ìƒì„¸ì ìˆ˜: [ê° ê¸°ì¤€ë³„ ì ìˆ˜ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„]
"""
            # API calls by model
            if model_name == "gpt":
                response = openai.ChatCompletion.create(
                    model=model_zoo[0],
                    messages=[{"role": "user", "content": evaluation_prompt}]
                )
                result_text = response.choices[0].message.content
            elif model_name == "gemini":
                response = gemini_model.generate_content(evaluation_prompt)
                result_text = response.text
            else:  # claude
                response = anthropic.messages.create(
                    model=model_zoo[2],
                    messages=[{"role": "user", "content": evaluation_prompt}]
                )
                result_text = response.content[0].text
            
            # Parse results
            parsed_result = self.parse_evaluation_result(result_text)
            
            # Cache results
            self.results_cache[cache_key] = parsed_result
            
            return parsed_result
            
        except Exception as e:
            st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "score": 0,
                "reason": f"í‰ê°€ ì‹¤íŒ¨: {str(e)}",
                "detailed_scores": [0] * len(self.scoring_config.criteria)
            }
    
    def parse_evaluation_result(self, result_text: str) -> Dict:
        """í‰ê°€ ê²°ê³¼ íŒŒì‹±"""
        try:
            lines = result_text.split('\n')
            
            score_line = next(l for l in lines if 'ì ìˆ˜:' in l)
            score = int(''.join(filter(str.isdigit, score_line)))
            
            reason_line = next(l for l in lines if 'ì´ìœ :' in l)
            reason = reason_line.split('ì´ìœ :')[1].strip()
            
            detailed_line = next(l for l in lines if 'ìƒì„¸ì ìˆ˜:' in l)
            detailed_scores = [
                int(s.strip()) for s in 
                detailed_line.split('ìƒì„¸ì ìˆ˜:')[1].strip().split(',')
            ]
            
            return {
                "score": score,
                "reason": reason,
                "detailed_scores": detailed_scores
            }
        except Exception as e:
            st.error(f"ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "score": 0,
                "reason": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                "detailed_scores": [0] * len(self.scoring_config.criteria)
            }

def generate_copy(prompt: str, model_name: str) -> str:
    """ê´‘ê³  ì¹´í”¼ ìƒì„±"""
    try:
        if model_name == "gpt":
            response = openai.ChatCompletion.create(
                model=model_zoo[0],
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content.strip()
        elif model_name == "gemini":
            response = gemini_model.generate_content(prompt)
            return response.text.strip()
        else:  # claude
            response = anthropic.messages.create(
                model=model_zoo[2],
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text.strip()
    except Exception as e:
        return f"ìƒì„± ì‹¤íŒ¨: {str(e)}"

def visualize_evaluation_results(results: Dict):
    """ê²°ê³¼ ì‹œê°í™”"""
    fig = px.radar(
        pd.DataFrame({
            'ê¸°ì¤€': st.session_state.scoring_config.criteria,
            'ì ìˆ˜': results['detailed_scores']
        }),
        r='ì ìˆ˜',
        theta='ê¸°ì¤€',
        title="í‰ê°€ ê¸°ì¤€ë³„ ì ìˆ˜"
    )
    return fig

# Streamlit app configuration
st.set_page_config(page_title="CopyStudio Lab", page_icon="ğŸ”¬", layout="wide")

# Load documents
DOCS = load_docs()

# Initial scoring configuration
DEFAULT_SCORING_CONFIG = ScoringConfig(
    prompt="""
ì£¼ì–´ì§„ ê´‘ê³  ì¹´í”¼ë¥¼ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
ê° ê¸°ì¤€ë³„ë¡œ 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , 
ìµœì¢… ì ìˆ˜ëŠ” ê° ê¸°ì¤€ì˜ í‰ê· ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    """,
    criteria=[
        "íƒ€ê²Ÿ ì í•©ì„±",
        "ë©”ì‹œì§€ ì „ë‹¬ë ¥",
        "ì°½ì˜ì„±",
        "ë¸Œëœë“œ ì í•©ì„±"
    ]
)

# Initialize session state
if 'scoring_config' not in st.session_state:
    st.session_state.scoring_config = DEFAULT_SCORING_CONFIG
if 'evaluator' not in st.session_state:
    st.session_state.evaluator = AdCopyEvaluator(st.session_state.scoring_config)
if 'history' not in st.session_state:
    st.session_state.history = []


# Sidebar configuration
with st.sidebar:
    st.header("âš™ï¸ í‰ê°€ ì‹œìŠ¤í…œ ì„¤ì •")
    
    with st.expander("í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
        new_prompt = st.text_area(
            "í‰ê°€ í”„ë¡¬í”„íŠ¸",
            value=st.session_state.scoring_config.prompt
        )
        new_criteria = st.text_area(
            "í‰ê°€ ê¸°ì¤€ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
            value="\n".join(st.session_state.scoring_config.criteria)
        )
        
        if st.button("í‰ê°€ ì„¤ì • ì—…ë°ì´íŠ¸"):
            new_config = ScoringConfig(
                prompt=new_prompt,
                criteria=[c.strip() for c in new_criteria.split('\n') if c.strip()]
            )
            st.session_state.scoring_config = new_config
            st.session_state.evaluator = AdCopyEvaluator(new_config)
            st.success("í‰ê°€ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # Target selection
    st.header("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •")
    
    selected_region = st.selectbox(
        "ì§€ì—­ ì„ íƒ",
        options=[""] + list(DOCS["region"].keys()),
        format_func=lambda x: "ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”" if x == "" else x
    )
    
    selected_generation = st.selectbox(
        "ì„¸ëŒ€ ì„ íƒ",
        options=[""] + list(DOCS["generation"].keys()),
        format_func=lambda x: "ì„¸ëŒ€ë¥¼ ì„ íƒí•˜ì„¸ìš”" if x == "" else x
    )
    
    st.subheader("MBTI ì„¤ì •")
    selected_mbti_groups = st.multiselect(
        "MBTI ê·¸ë£¹ ì„ íƒ",
        options=MBTI_GROUPS.keys()
    )
    
    selected_mbti = []
    for group in selected_mbti_groups:
        selected_mbti.extend(MBTI_GROUPS[group])

# Main content
col1, col2 = st.columns([3, 2])

with col1:
    st.subheader("ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì‘ì„±")
    
    # Generate base prompt
    base_prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

[ì§€ì—­ ì •ë³´]
{DOCS["region"].get(selected_region, "ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")}

[ì„¸ëŒ€ íŠ¹ì„±]
{DOCS["generation"].get(selected_generation, "ì„¸ëŒ€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")}
"""
    
    if selected_mbti:
        mbti_info = "\n".join([
            f"[{mbti.upper()} íŠ¹ì„±]\n{DOCS['mbti'].get(mbti.lower(), 'ì •ë³´ ì—†ìŒ')}"
            for mbti in selected_mbti
        ])
        base_prompt += f"\n[MBTI íŠ¹ì„±]\n{mbti_info}"
    
    base_prompt += """
ìš”êµ¬ì‚¬í•­:
1. ì„ íƒëœ íƒ€ê²Ÿì¸µì˜ íŠ¹ì„±ì„ ë°˜ì˜í•œ í†¤ì•¤ë§¤ë„ˆë¡œ ì‘ì„±
2. ì¹´í”¼ëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
3. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©
4. ì„ íƒëœ ì§€ì—­ì˜ íŠ¹ì§•ì„ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„
"""
    
    prompt = st.text_area(
        "ìƒì„± í”„ë¡¬í”„íŠ¸",
        value=base_prompt,
        height=300
    )
    
    if st.button("ğŸ¨ ê´‘ê³  ì¹´í”¼ ìƒì„±", use_container_width=True):
        if not selected_region or not selected_generation:
            st.error("ì§€ì—­ê³¼ ì„¸ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("AI ëª¨ë¸ì´ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                # Generate copies
                results = {
                    model: generate_copy(prompt, model)
                    for model in ["gpt", "gemini", "claude"]
                }
                
                # Evaluate copies
                evaluations = {
                    model: st.session_state.evaluator.evaluate(copy, model)
                    for model, copy in results.items()
                }
                
                # Save results
                experiment_data = {
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "prompt": prompt,
                    "results": results,
                    "evaluations": evaluations,
                    "settings": {
                        "region": selected_region,
                        "generation": selected_generation,
                        "mbti": selected_mbti
                    }
                }
                st.session_state.history.append(experiment_data)
with col2:
    st.subheader("ğŸ“Š ì‹¤í—˜ ê²°ê³¼")
    
    for idx, experiment in enumerate(reversed(st.session_state.history)):
        with st.container():
            st.markdown(f"""
            <div class="result-card">
                <p style='color: #64748b; font-size: 0.875rem;'>{experiment['timestamp']}</p>
                <div style='margin: 1rem 0;'>
            """, unsafe_allow_html=True)
            
            for model in ["gpt", "gemini", "claude"]:
                result = experiment['results'][model]
                evaluation = experiment['evaluations'][model]
                
                st.markdown(f"""
                <div style='margin-bottom: 1.5rem;'>
                    <span class="model-tag {model}-tag">{model.upper()}</span>
                    <div style='background-color: #f8fafc; padding: 1rem; border-radius: 8px; margin: 0.5rem 0;'>
                        {result}
                    </div>
                    <div class="evaluation-score">
                        ì ìˆ˜: {evaluation['score']}ì 
                    </div>
                    <div class="evaluation-reason">
                        {evaluation['reason']}
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                fig = visualize_evaluation_results(evaluation)
                st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("</div></div>", unsafe_allow_html=True)
