import streamlit as st
import openai
import google.generativeai as genai
from anthropic import Anthropic
from datetime import datetime
import pandas as pd
import json
import pathlib
import plotly.express as px
from typing import Dict, List, Optional
from dataclasses import dataclass

# Initialize API keys from Streamlit secrets
openai.api_key = st.secrets["chatgpt"]
genai.configure(api_key=st.secrets["gemini"])
anthropic = Anthropic(api_key=st.secrets["claude"])

# Gemini model configuration
gemini_model = genai.GenerativeModel('gemini-1.5-pro-exp-0827')


# Load documents from docs folder
def load_docs() -> Dict[str, Dict[str, str]]:
    docs_path = pathlib.Path("docs")
    docs = {
        "region": {},
        "generation": {},
        "mbti": {}
    }
    
    # Load region docs
    region_path = docs_path / "regions"
    if region_path.exists():
        for file in region_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["region"][file.stem] = f.read()
    
    # Load generation docs
    generation_path = docs_path / "generations"
    if generation_path.exists():
        for file in generation_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["generation"][file.stem] = f.read()
    
    # Load MBTI docs
    mbti_path = docs_path / "mbti"
    if mbti_path.exists():
        for file in mbti_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["mbti"][file.stem] = f.read()
    
    return docs

@dataclass
class ScoringConfig:
    """í‰ê°€ ì‹œìŠ¤í…œ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    prompt: str
    criteria: List[str]
    min_score: int = 0
    max_score: int = 100
    
    def to_dict(self) -> dict:
        return {
            "prompt": self.prompt,
            "criteria": self.criteria,
            "min_score": self.min_score,
            "max_score": self.max_score
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'ScoringConfig':
        return cls(**data)

class AdCopyEvaluator:
    """ê´‘ê³  ì¹´í”¼ í‰ê°€ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, scoring_config: ScoringConfig):
        self.scoring_config = scoring_config
        self.results_cache = {}
    
    def evaluate(self, copy: str, model_name: str) -> Dict:
        """í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ íŒŒì‹±"""
        try:
            # ìºì‹œëœ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            cache_key = f"{copy}_{model_name}"
            if cache_key in self.results_cache:
                return self.results_cache[cache_key]
            
            # í‰ê°€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            evaluation_prompt = f"""
{self.scoring_config.prompt}

í‰ê°€ ëŒ€ìƒ ì¹´í”¼: {copy}

í‰ê°€ ê¸°ì¤€:
{chr(10).join(f'- {criterion}' for criterion in self.scoring_config.criteria)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì ìˆ˜: [0-100 ì‚¬ì´ì˜ ìˆ«ì]
ì´ìœ : [í‰ê°€ ê·¼ê±°]
ìƒì„¸ì ìˆ˜: [ê° ê¸°ì¤€ë³„ ì ìˆ˜ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„]
"""
            # ëª¨ë¸ë³„ API í˜¸ì¶œ
            if model_name == "gpt":
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": evaluation_prompt}]
                )
                result_text = response.choices[0].message.content
            elif model_name == "gemini":
                response = gemini_model.generate_content(evaluation_prompt)
                result_text = response.text
            else:  # claude
                response = anthropic.messages.create(
                    model="claude-3-5-haiku-20241022",
                    messages=[{"role": "user", "content": evaluation_prompt}]
                )
                result_text = response.content[0].text
            
            # ê²°ê³¼ íŒŒì‹±
            parsed_result = self.parse_evaluation_result(result_text)
            
            # ìºì‹œì— ì €ì¥
            self.results_cache[cache_key] = parsed_result
            
            return parsed_result
            
        except Exception as e:
            st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "score": 0,
                "reason": f"í‰ê°€ ì‹¤íŒ¨: {str(e)}",
                "detailed_scores": [0] * len(self.scoring_config.criteria)
            }
    
    def parse_evaluation_result(self, result_text: str) -> Dict:
        """í‰ê°€ ê²°ê³¼ íŒŒì‹± ë¡œì§"""
        try:
            lines = result_text.split('\n')
            
            # ì ìˆ˜ ì¶”ì¶œ
            score_line = next(l for l in lines if 'ì ìˆ˜:' in l)
            score = int(''.join(filter(str.isdigit, score_line)))
            
            # ì´ìœ  ì¶”ì¶œ
            reason_line = next(l for l in lines if 'ì´ìœ :' in l)
            reason = reason_line.split('ì´ìœ :')[1].strip()
            
            # ìƒì„¸ ì ìˆ˜ ì¶”ì¶œ
            detailed_line = next(l for l in lines if 'ìƒì„¸ì ìˆ˜:' in l)
            detailed_scores = [
                int(s.strip()) for s in 
                detailed_line.split('ìƒì„¸ì ìˆ˜:')[1].strip().split(',')
            ]
            
            return {
                "score": score,
                "reason": reason,
                "detailed_scores": detailed_scores
            }
        except Exception as e:
            st.error(f"ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "score": 0,
                "reason": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                "detailed_scores": [0] * len(self.scoring_config.criteria)
            }

def generate_copy(prompt: str, model_name: str) -> str:
    """ê´‘ê³  ì¹´í”¼ ìƒì„± í•¨ìˆ˜"""
    try:
        if model_name == "gpt":
            response = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content.strip()
        elif model_name == "gemini":
            response = gemini_model.generate_content(prompt)
            return response.text.strip()
        else:  # claude
            response = anthropic.messages.create(
                model="claude-3-5-haiku-20241022",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text.strip()
    except Exception as e:
        return f"ìƒì„± ì‹¤íŒ¨: {str(e)}"

def visualize_evaluation_results(results: Dict):
    """ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜"""
    fig = px.radar(
        pd.DataFrame({
            'ê¸°ì¤€': st.session_state.scoring_config.criteria,
            'ì ìˆ˜': results['detailed_scores']
        }),
        r='ì ìˆ˜',
        theta='ê¸°ì¤€',
        title="í‰ê°€ ê¸°ì¤€ë³„ ì ìˆ˜"
    )
    return fig

# Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="CopyStudio Lab", page_icon="ğŸ”¬", layout="wide")

# ë¬¸ì„œ ë¡œë“œ
DOCS = load_docs()

# ì´ˆê¸° í‰ê°€ ì„¤ì •
DEFAULT_SCORING_CONFIG = ScoringConfig(
    prompt="""
ì£¼ì–´ì§„ ê´‘ê³  ì¹´í”¼ë¥¼ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
ê° ê¸°ì¤€ë³„ë¡œ 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , 
ìµœì¢… ì ìˆ˜ëŠ” ê° ê¸°ì¤€ì˜ í‰ê· ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    """,
    criteria=[
        "íƒ€ê²Ÿ ì í•©ì„±",
        "ë©”ì‹œì§€ ì „ë‹¬ë ¥",
        "ì°½ì˜ì„±",
        "ë¸Œëœë“œ ì í•©ì„±"
    ]
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'scoring_config' not in st.session_state:
    st.session_state.scoring_config = DEFAULT_SCORING_CONFIG
if 'evaluator' not in st.session_state:
    st.session_state.evaluator = AdCopyEvaluator(st.session_state.scoring_config)
if 'history' not in st.session_state:
    st.session_state.history = []
if 'selected_docs' not in st.session_state:
    st.session_state.selected_docs = {
        'region': '',
        'generation': '',
        'mbti': []
    }

# ë©”ì¸ UI
st.title("ğŸ”¬ ê´‘ê³  ì¹´í”¼ ìƒì„± ì—°êµ¬ í”Œë«í¼")

# ì‚¬ì´ë“œë°”: í‰ê°€ ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ í‰ê°€ ì‹œìŠ¤í…œ ì„¤ì •")
    
    with st.expander("í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
        new_prompt = st.text_area(
            "í‰ê°€ í”„ë¡¬í”„íŠ¸",
            value=st.session_state.scoring_config.prompt
        )
        new_criteria = st.text_area(
            "í‰ê°€ ê¸°ì¤€ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
            value="\n".join(st.session_state.scoring_config.criteria)
        )
        
        if st.button("í‰ê°€ ì„¤ì • ì—…ë°ì´íŠ¸"):
            new_config = ScoringConfig(
                prompt=new_prompt,
                criteria=[c.strip() for c in new_criteria.split('\n') if c.strip()]
            )
            st.session_state.scoring_config = new_config
            st.session_state.evaluator = AdCopyEvaluator(new_config)
            st.success("í‰ê°€ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # íƒ€ê²Ÿ ì„¤ì •
    st.header("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •")
    
    selected_region = st.selectbox(
        "ì§€ì—­ ì„ íƒ",
        options=[""] + list(DOCS["region"].keys()),
        format_func=lambda x: "ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”" if x == "" else x
    )
    
    selected_generation = st.selectbox(
        "ì„¸ëŒ€ ì„ íƒ",
        options=[""] + list(DOCS["generation"].keys()),
        format_func=lambda x: "ì„¸ëŒ€ë¥¼ ì„ íƒí•˜ì„¸ìš”" if x == "" else x
    )
    
    selected_mbti_groups = st.multiselect(
        "MBTI ì„ íƒ",
        options=list(DOCS["mbti"].keys())
    )

# ë©”ì¸ ì»¨í…ì¸ 
col1, col2 = st.columns([3, 2])

with col1:
    st.subheader("ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì‘ì„±")
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    base_prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

[ì§€ì—­ ì •ë³´]
{DOCS["region"].get(selected_region, "ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")}

[ì„¸ëŒ€ íŠ¹ì„±]
{DOCS["generation"].get(selected_generation, "ì„¸ëŒ€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")}
"""
    
    if selected_mbti_groups:
        mbti_info = "\n".join([
            f"[{mbti.upper()} íŠ¹ì„±]\n{DOCS['mbti'].get(mbti, 'ì •ë³´ ì—†ìŒ')}"
            for mbti in selected_mbti_groups
        ])
        base_prompt += f"\n[MBTI íŠ¹ì„±]\n{mbti_info}"
    
    prompt = st.text_area(
        "ìƒì„± í”„ë¡¬í”„íŠ¸",
        value=base_prompt,
        height=300
    )
    
    if st.button("ğŸ¨ ê´‘ê³  ì¹´í”¼ ìƒì„±", use_container_width=True):
        if not selected_region or not selected_generation:
            st.error("ì§€ì—­ê³¼ ì„¸ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("AI ëª¨ë¸ì´ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                # ê° ëª¨ë¸ì—ì„œ ì¹´í”¼ ìƒì„±
                results = {
                    model: generate_copy(prompt, model)
                    for model in ["gpt", "gemini", "claude"]
                }
                
                # í‰ê°€ ìˆ˜í–‰
                evaluations = {
                    model: st.session_state.evaluator.evaluate(copy, model)
                    for model, copy in results.items()
                }
                
                # ê²°ê³¼ ì €ì¥
                experiment_data = {
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "prompt": prompt,
                    "results": results,
                    "evaluations": evaluations,
                    "settings": {
                        "region": selected_region,
                        "generation": selected_generation,
                        "mbti": selected_mbti_groups
                    }
                }
                st.session_state.history.append(experiment_data)

with col2:
    st.subheader("ğŸ“Š ì‹¤í—˜ ê²°ê³¼")
    
    for idx, experiment in enumerate(reversed(st.session_state.history)):
        with st.expander(f"ì‹¤í—˜ {len(st.session_state.history)-idx}", expanded=idx==0):
            st.text(f"ì‹œê°„: {experiment['timestamp']}")
            
            for model in ["gpt", "gemini", "claude"]:
                result = experiment['results'][model]
                evaluation = experiment['evaluations'][model]
                
                st.markdown(f"""
                **{model.upper()}**
                ```
                {result}
                ```
                ì ìˆ˜: {evaluation['score']}
                ì´ìœ : {evaluation['reason']}
                """)
                
                fig = visualize_evaluation_results(evaluation)
                st.plotly_chart(fig, use_container_width=True)

# ì‹¤í—˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
if st.session_state.history:
    st.download_button(
        "ğŸ“¥ ì‹¤í—˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
        data=json.dumps(st.session_state.history, indent=2, ensure_ascii=False),
        file_name="experiment_results.json",
        mime="application/json"
    )
        
