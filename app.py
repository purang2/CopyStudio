import streamlit as st
import openai
from google.generativeai import GenerativeModel
import anthropic
import json
from datetime import datetime
import pandas as pd

# Page config
st.set_page_config(
    page_title="CopyStudio",
    page_icon="âœ¨",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Noto Sans KR', sans-serif;
    }
    
    .stButton button {
        background-color: #4CACBC;
        color: white;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        border: none;
        font-weight: 500;
    }
    
    .prompt-container {
        border: 2px solid #4CACBC;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    
    .result-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }
    
    .model-tag {
        font-size: 0.8em;
        padding: 3px 8px;
        border-radius: 15px;
        color: white;
    }
    
    .gpt-tag { background-color: #10a37f; }
    .gemini-tag { background-color: #4285f4; }
    .claude-tag { background-color: #8e44ad; }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'history' not in st.session_state:
    st.session_state.history = []
if 'region_info' not in st.session_state:
    st.session_state.region_info = ""
if 'mz_info' not in st.session_state:
    st.session_state.mz_info = ""

# Header
st.title("ğŸ¯ ê´€ê´‘ì§€ ê´‘ê³  ì¹´í”¼ ìƒì„±ê¸°")
st.markdown("#### MZì„¸ëŒ€ë¥¼ ìœ„í•œ ë§ì¶¤í˜• ê´‘ê³  ì¹´í”¼ ìƒì„± ë° í‰ê°€ ì‹œìŠ¤í…œ")

# Sidebar for document uploads
with st.sidebar:
    st.header("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")
    
    region_file = st.file_uploader("ì§€ì—­ ì •ë³´ ë¬¸ì„œ (TXT)", type=['txt'])
    if region_file:
        st.session_state.region_info = region_file.read().decode('utf-8')
        st.success("ì§€ì—­ ì •ë³´ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    mz_file = st.file_uploader("MZì„¸ëŒ€ ì—¬í–‰ ì„±í–¥ ë¬¸ì„œ (TXT)", type=['txt'])
    if mz_file:
        st.session_state.mz_info = mz_file.read().decode('utf-8')
        st.success("MZì„¸ëŒ€ ì •ë³´ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

# Main content
col1, col2 = st.columns([3, 2])

with col1:
    st.subheader("ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì„¤ì •")
    
    default_prompt = """
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ MZì„¸ëŒ€ë¥¼ ìœ„í•œ ê´€ê´‘ì§€ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
1. ì¹´í”¼ëŠ” ì Šê³  íŠ¸ë Œë””í•œ í†¤ì•¤ë§¤ë„ˆë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
2. ì¹´í”¼ëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•´ì£¼ì„¸ìš”
4. MZì„¸ëŒ€ì˜ ê´€ì‹¬ì‚¬ì™€ ì—¬í–‰ ì„±í–¥ì„ ë°˜ì˜í•´ì£¼ì„¸ìš”
"""
    
    prompt = st.text_area(
        "í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ë³´ì„¸ìš”",
        value=default_prompt,
        height=200,
        help="í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ë” ë‚˜ì€ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±í•´ë³´ì„¸ìš”!"
    )

    if st.button("ğŸ¨ ê´‘ê³  ì¹´í”¼ ìƒì„±í•˜ê¸°", use_container_width=True):
        with st.spinner("AI ëª¨ë¸ì´ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
            # Simulate API calls (replace with actual API calls)
            results = {
                'gpt': "âœ¨ ì¸ìƒìƒ· ê±´ì§€ëŸ¬ ë– ë‚˜ëŠ” í™í•œ ì—¬í–‰, ìš°ë¦¬ ë™ë„¤ê°€ ê¸°ë‹¤ë ¤ìš”!",
                'gemini': "ğŸŒŠ MZë“¤ì˜ í•«í”Œë ˆì´ìŠ¤, ìš°ë¦¬ ë™ë„¤ì—ì„œ íŠ¸ë Œë””í•œ ì¼ìƒ íƒˆì¶œ!",
                'claude': "ğŸ¡ ë†€ë©´ì„œ ë°°ìš°ëŠ” ìš°ë¦¬ ë™ë„¤ ìŠ¤í† ë¦¬, ë‹¹ì‹ ì˜ ì¸ìŠ¤íƒ€ë¥¼ ì±„ì›Œë“œë¦½ë‹ˆë‹¤"
            }
            
            # Evaluate copies
            evaluation_prompt = f"""
ë‹¤ìŒ ê´‘ê³  ì¹´í”¼ë“¤ì„ 0-100ì  ì‚¬ì´ë¡œ í‰ê°€í•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
í‰ê°€ ê¸°ì¤€:
1. MZì„¸ëŒ€ íƒ€ê²ŸíŒ… ì ì ˆì„±
2. ë©”ì‹œì§€ ì „ë‹¬ë ¥
3. ì°½ì˜ì„±ê³¼ ì°¸ì‹ ì„±
4. íŠ¸ë Œë””í•¨

í˜•ì‹:
ì ìˆ˜: [ìˆ«ì]
ì´ìœ : [ì„¤ëª…]
"""
            
            # Simulate evaluations (replace with actual API calls)
            evaluations = {
                'gpt': {'score': 85, 'reason': "ì¸ìƒìƒ·ì´ë¼ëŠ” í‚¤ì›Œë“œì™€ í™í•œì´ë¼ëŠ” í‘œí˜„ì´ MZì„¸ëŒ€ì˜ ê´€ì‹¬ì‚¬ë¥¼ ì •í™•íˆ íƒ€ê²ŸíŒ…í–ˆìŠµë‹ˆë‹¤."},
                'gemini': {'score': 88, 'reason': "í•«í”Œë ˆì´ìŠ¤ì™€ íŠ¸ë Œë””ë€ ë‹¨ì–´ ì„ íƒì´ ì ì ˆí•˜ë©°, ì¼ìƒ íƒˆì¶œì´ë¼ëŠ” ì»¨ì…‰ì´ ë§¤ë ¥ì ì…ë‹ˆë‹¤."},
                'claude': {'score': 82, 'reason': "ì¸ìŠ¤íƒ€ê·¸ë¨ ì—°ê³„ ë§ˆì¼€íŒ… ì ‘ê·¼ì´ ì¢‹ìœ¼ë‚˜, ë‹¤ì†Œ ê¸´ ë¬¸ì¥ êµ¬ì¡°ê°€ ì•„ì‰½ìŠµë‹ˆë‹¤."}
            }
            
            # Save to history
            st.session_state.history.append({
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'prompt': prompt[:20] + "...",
                'results': results,
                'evaluations': evaluations
            })

with col2:
    st.subheader("ğŸ“Š ìƒì„± ê²°ê³¼ ê¸°ë¡")
    
    for idx, entry in enumerate(reversed(st.session_state.history)):
        with st.expander(f"ğŸ“ {entry['prompt']} ({entry['timestamp']})"):
            for model, copy in entry['results'].items():
                eval_data = entry['evaluations'][model]
                
                st.markdown(f"""
                <div class="result-card">
                    <span class="model-tag {model}-tag">{model.upper()}</span>
                    <p>{copy}</p>
                    <details>
                        <summary>í‰ê°€ ì ìˆ˜: {eval_data['score']}</summary>
                        <p>{eval_data['reason']}</p>
                    </details>
                </div>
                """, unsafe_allow_html=True)

# Display prompt history with rankings
st.subheader("ğŸ† í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ìˆœìœ„")
if st.session_state.history:
    history_df = pd.DataFrame([
        {
            'í”„ë¡¬í”„íŠ¸': h['prompt'],
            'í‰ê·  ì ìˆ˜': sum(h['evaluations'][m]['score'] for m in ['gpt', 'gemini', 'claude']) / 3,
            'ìµœê³  ì ìˆ˜': max(h['evaluations'][m]['score'] for m in ['gpt', 'gemini', 'claude']),
            'ìƒì„± ì‹œê°„': h['timestamp']
        }
        for h in st.session_state.history
    ])
    
    st.dataframe(
        history_df.sort_values('í‰ê·  ì ìˆ˜', ascending=False),
        use_container_width=True,
        hide_index=True
    )
