import streamlit as st
#import openai
from openai import OpenAI
import google.generativeai as genai
from anthropic import Anthropic
from datetime import datetime
import pandas as pd
import json
import pathlib
from typing import Dict, List, Optional
from dataclasses import dataclass

import plotly.express as px 
import plotly.graph_objects as go


# Page config must be the first Streamlit command
st.set_page_config(
    page_title="CopyStudio Lab - ê´‘ê³  ì¹´í”¼ ì—°êµ¬ì†Œ", 
    page_icon="ğŸ”¬", 
    layout="wide"
)

# Initialize API keys from Streamlit secrets
#openai.api_key = st.secrets["chatgpt"]
genai.configure(api_key=st.secrets["gemini"])
anthropic = Anthropic(api_key=st.secrets["claude"])
client = OpenAI(api_key=st.secrets["chatgpt"])  # API í‚¤ ì…ë ¥



#ì±—-ì œ-í´ ìˆœì„œ ì˜¤ì™€ì—´
model_zoo = ['gpt-4o',
             'gemini-1.5-pro-exp-0827',
             'claude-3-5-haiku-20241022']

# Gemini model configuration
gemini_model = genai.GenerativeModel(model_zoo[1])


# CSS 
st.markdown("""
<style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');

    /* ì „ì²´ í°íŠ¸ ë° ìƒ‰ìƒ ìŠ¤íƒ€ì¼ */
    [data-testid="stAppViewContainer"] {
        font-family: 'Pretendard', sans-serif;
        background-color: #f8fafc;
    }

    /* í—¤ë” ìŠ¤íƒ€ì¼ë§ */
    h1, h2, h3, h4, h5, h6 {
        font-family: 'Pretendard', sans-serif;
        font-weight: 700;
        color: #1e293b;
    }

    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .stCard {
        border-radius: 15px;
        box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1), 0 2px 4px -1px rgba(0,0,0,0.06);
        padding: 1rem;
        background-color: white;
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ */
    .stButton > button {
        background-color: #3b82f6;
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.2s ease;
    }
    .stButton > button:hover {
        background-color: #2563eb;
        transform: translateY(-1px);
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ë§ */
    [data-testid="stSidebar"] {
        background-color: white;
        border-right: 1px solid #e2e8f0;
        padding: 2rem 1rem;
    }
    [data-testid="stSidebar"] .stMarkdown {
        padding: 0.5rem 0;
    }

    /* ì…€ë ‰íŠ¸ë°•ìŠ¤ ìŠ¤íƒ€ì¼ë§ */
    .stSelectbox > div > div {
        background-color: white;
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        padding: 0.5rem;
    }

    /* ê²°ê³¼ ì¹´ë“œ ìŠ¤íƒ€ì¼ë§ */
    .result-card {
        background-color: white;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    /* ëª¨ë¸ íƒœê·¸ ìŠ¤íƒ€ì¼ë§ */
    .model-tag {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    .gpt-tag { background-color: #10b981; color: white; }
    .gemini-tag { background-color: #6366f1; color: white; }
    .claude-tag { background-color: #8b5cf6; color: white; }

    /* í‰ê°€ ê²°ê³¼ ìŠ¤íƒ€ì¼ë§ */
    .evaluation-score {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1e293b;
    }
    .evaluation-reason {
        color: #64748b;
        font-size: 0.875rem;
        line-height: 1.5;
        margin-top: 0.5rem;
    }

    /* í…ìŠ¤íŠ¸ ì˜ì—­ ìŠ¤íƒ€ì¼ë§ */
    .stTextArea > div > textarea {
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        padding: 1rem;
        font-family: 'Pretendard', sans-serif;
    }

    /* ë¡œë”© ìŠ¤í”¼ë„ˆ ìŠ¤íƒ€ì¼ë§ */
    .stSpinner > div {
        border-color: #3b82f6;
    }

    /* íƒ­ ìŠ¤íƒ€ì¼ë§ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: white;
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        color: #1e293b;
        font-weight: 500;
    }
    .stTabs [aria-selected="true"] {
        background-color: #3b82f6;
        color: white;
        border: none;
    }

    /* ê²½ê³ /ì„±ê³µ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ */
    .stAlert {
        border-radius: 8px;
        padding: 1rem;
    }
    .stSuccess {
        background-color: #ecfdf5;
        color: #065f46;
    }
    .stError {
        background-color: #fef2f2;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)








# MBTI ê·¸ë£¹ ìƒìˆ˜ ì •ì˜
MBTI_GROUPS = {
    "ë¶„ì„ê°€í˜•": ["INTJ", "INTP", "ENTJ", "ENTP"],
    "ì™¸êµê´€í˜•": ["INFJ", "INFP", "ENFJ", "ENFP"],
    "ê´€ë¦¬ìí˜•": ["ISTJ", "ISFJ", "ESTJ", "ESFJ"],
    "íƒí—˜ê°€í˜•": ["ISTP", "ISFP", "ESTP", "ESFP"]
}

# MBTI ìƒìˆ˜ ìˆ˜ì •
MBTI_TYPES = [
    "INTJ", "INTP", "ENTJ", "ENTP",
    "INFJ", "INFP", "ENFJ", "ENFP",
    "ISTJ", "ISFJ", "ESTJ", "ESFJ",
    "ISTP", "ISFP", "ESTP", "ESFP"
]


def create_adaptive_prompt(
    city_doc: str, 
    target_generation: str, 
    mbti: str = None,  # ë‹¨ì¼ MBTI ë¬¸ìì—´ë¡œ ë³€ê²½
    include_mbti: bool = False
) -> str:
    base_prompt = f"""
ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤. 
ì•„ë˜ ì œê³µë˜ëŠ” ë„ì‹œ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ë§¤ë ¥ì ì¸ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì¹´í”¼ëŠ” ìì—°ìŠ¤ëŸ½ê³  ì°½ì˜ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

[ë„ì‹œ ì •ë³´]
{city_doc}

[ì¹´í”¼ ì‘ì„± ê°€ì´ë“œë¼ì¸]
1. ìœ„ ì •ë³´ëŠ” ì˜ê°ì„ ì–»ê¸° ìœ„í•œ ì°¸ê³  ìë£Œì…ë‹ˆë‹¤.
2. ë„ì‹œì˜ í•µì‹¬ ë§¤ë ¥ì„ í¬ì°©í•´ ì‹ ì„ í•œ ê´€ì ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
3. íƒ€ê²Ÿì¸µì— ë§ëŠ” í†¤ì•¤ë§¤ë„ˆë¥¼ ì‚¬ìš©í•˜ë˜, ì •ë³´ì˜ ë‚˜ì—´ì€ í”¼í•´ì£¼ì„¸ìš”.
4. ê°ì„±ì  ê³µê°ê³¼ êµ¬ì²´ì  íŠ¹ì§•ì´ ì¡°í™”ë¥¼ ì´ë£¨ë„ë¡ í•´ì£¼ì„¸ìš”.

[íƒ€ê²Ÿ ì •ë³´]
ì„¸ëŒ€: {target_generation}"""

    if include_mbti and mbti:
        mbti_prompt = f"""
MBTI: {mbti}
íŠ¹ë³„ ê³ ë ¤ì‚¬í•­: 
- {mbti} ì„±í–¥ì˜ ì—¬í–‰ ì„ í˜¸ë„ë¥¼ ë°˜ì˜
- í•´ë‹¹ ì„±í–¥ì˜ ê´€ì‹¬ì‚¬ì™€ ê°€ì¹˜ê´€ ê³ ë ¤"""
        base_prompt += mbti_prompt

    base_prompt += """

[ì œì•½ì‚¬í•­]
- í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
- ì´ëª¨ì§€ 1-2ê°œ í¬í•¨
- ë„ì‹œë§Œì˜ ë…íŠ¹í•œ íŠ¹ì§• í•˜ë‚˜ ì´ìƒ í¬í•¨
- í´ë¦¬ì…°ë‚˜ ì§„ë¶€í•œ í‘œí˜„ ì§€ì–‘
"""
    return base_prompt


# ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜ ìˆ˜ì •
def load_docs() -> Dict[str, Dict[str, str]]:
    docs_path = pathlib.Path("docs")
    docs = {
        "region": {},
        "generation": {},
        "mbti": {}
    }
    
    # ì§€ì—­ ë¬¸ì„œ ë¡œë“œ
    region_path = docs_path / "regions"
    if region_path.exists():
        for file in region_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["region"][file.stem] = f.read()
    
    # ì„¸ëŒ€ ë¬¸ì„œ ë¡œë“œ
    generation_path = docs_path / "generations"
    if generation_path.exists():
        for file in generation_path.glob("*.txt"):
            with open(file, "r", encoding="utf-8") as f:
                docs["generation"][file.stem] = f.read()
    
    # MBTI ë¬¸ì„œ ë¡œë“œ (ë‹¨ì¼ íŒŒì¼)
    mbti_file = docs_path / "mbti" / "mbti_all.txt"
    if mbti_file.exists():
        with open(mbti_file, "r", encoding="utf-8") as f:
            content = f.read()
            # ê° MBTI ì„¹ì…˜ íŒŒì‹±
            for group in MBTI_GROUPS.keys():
                group_start = content.find(f"[{group}]")
                next_group_start = len(content)
                for other_group in MBTI_GROUPS.keys():
                    if other_group != group:
                        pos = content.find(f"[{other_group}]")
                        if pos > group_start and pos < next_group_start:
                            next_group_start = pos
                
                group_content = content[group_start:next_group_start].strip()
                for mbti in MBTI_GROUPS[group]:
                    mbti_start = group_content.find(mbti)
                    next_mbti_start = len(group_content)
                    for other_mbti in MBTI_GROUPS[group]:
                        if other_mbti != mbti:
                            pos = group_content.find(other_mbti)
                            if pos > mbti_start and pos < next_mbti_start:
                                next_mbti_start = pos
                    
                    mbti_content = group_content[mbti_start:next_mbti_start].strip()
                    docs["mbti"][mbti.lower()] = mbti_content
    
    return docs


@dataclass
class ScoringConfig:
    """í‰ê°€ ì‹œìŠ¤í…œ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    prompt: str
    criteria: List[str]
    min_score: int = 0
    max_score: int = 100
    
    def to_dict(self) -> dict:
        return {
            "prompt": self.prompt,
            "criteria": self.criteria,
            "min_score": self.min_score,
            "max_score": self.max_score
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'ScoringConfig':
        return cls(**data)

class AdCopyEvaluator:
    """ê´‘ê³  ì¹´í”¼ í‰ê°€ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, scoring_config: ScoringConfig):
        self.scoring_config = scoring_config
        self.results_cache = {}
    
    def evaluate(self, copy: str, model_name: str) -> Dict:
        """í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ íŒŒì‹±"""
        try:
            # Check cache
            cache_key = f"{copy}_{model_name}"
            if cache_key in self.results_cache:
                return self.results_cache[cache_key]
            
            # Construct evaluation prompt
            evaluation_prompt = f"""
{self.scoring_config.prompt}

í‰ê°€ ëŒ€ìƒ ì¹´í”¼: {copy}

í‰ê°€ ê¸°ì¤€:
{chr(10).join(f'- {criterion}' for criterion in self.scoring_config.criteria)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì ìˆ˜: [0-100 ì‚¬ì´ì˜ ìˆ«ì]
ì´ìœ : [í‰ê°€ ê·¼ê±°]
ìƒì„¸ì ìˆ˜: [ê° ê¸°ì¤€ë³„ ì ìˆ˜ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„]
"""
            # API calls by model
            if model_name == "gpt":
                #response = openai.ChatCompletion.create(
                response = client.chat.completions.create(
                    model=model_zoo[0],
                    messages=[{"role": "user", "content": evaluation_prompt}]
                )
                result_text = response.choices[0].message.content
            elif model_name == "gemini":
                response = gemini_model.generate_content(evaluation_prompt)
                result_text = response.text
            else:  # claude
                response = anthropic.messages.create(
                    model=model_zoo[2],
                    messages=[{"role": "user", "content": evaluation_prompt}]
                )
                result_text = response.content[0].text
            
            # Parse results
            parsed_result = self.parse_evaluation_result(result_text)
            
            # Cache results
            self.results_cache[cache_key] = parsed_result
            
            return parsed_result
            
        except Exception as e:
            st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "score": 0,
                "reason": f"í‰ê°€ ì‹¤íŒ¨: {str(e)}",
                "detailed_scores": [0] * len(self.scoring_config.criteria)
            }
    
    def parse_evaluation_result(self, result_text: str) -> Dict:
        """í‰ê°€ ê²°ê³¼ íŒŒì‹±"""
        try:
            lines = result_text.split('\n')
            
            score_line = next(l for l in lines if 'ì ìˆ˜:' in l)
            score = int(''.join(filter(str.isdigit, score_line)))
            
            reason_line = next(l for l in lines if 'ì´ìœ :' in l)
            reason = reason_line.split('ì´ìœ :')[1].strip()
            
            detailed_line = next(l for l in lines if 'ìƒì„¸ì ìˆ˜:' in l)
            detailed_scores = [
                int(s.strip()) for s in 
                detailed_line.split('ìƒì„¸ì ìˆ˜:')[1].strip().split(',')
            ]
            
            return {
                "score": score,
                "reason": reason,
                "detailed_scores": detailed_scores
            }
        except Exception as e:
            st.error(f"ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "score": 0,
                "reason": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                "detailed_scores": [0] * len(self.scoring_config.criteria)
            }

def generate_copy(prompt: str, model_name: str) -> str:
    """ê´‘ê³  ì¹´í”¼ ìƒì„±"""
    try:
        if model_name == "gpt":
            #response = openai.ChatCompletion.create(
            response = client.chat.completions.create(
                model=model_zoo[0],
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content.strip()
        elif model_name == "gemini":
            response = gemini_model.generate_content(prompt)
            return response.text.strip()
        else:  # claude
            response = anthropic.messages.create(
                model=model_zoo[2],
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text.strip()
    except Exception as e:
        return f"ìƒì„± ì‹¤íŒ¨: {str(e)}"
def visualize_evaluation_results(results: Dict):
    """ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜"""
    fig = go.Figure(data=go.Scatterpolar(
        r=results['detailed_scores'],
        theta=st.session_state.scoring_config.criteria,
        fill='toself',
        name='í‰ê°€ ì ìˆ˜'
    ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )
        ),
        showlegend=False,
        title="í‰ê°€ ê¸°ì¤€ë³„ ì ìˆ˜"
    )
    return fig

# Load documents
DOCS = load_docs()

# Initial scoring configuration
DEFAULT_SCORING_CONFIG = ScoringConfig(
    prompt="""
ì£¼ì–´ì§„ ê´‘ê³  ì¹´í”¼ë¥¼ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
ê° ê¸°ì¤€ë³„ë¡œ 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , 
ìµœì¢… ì ìˆ˜ëŠ” ê° ê¸°ì¤€ì˜ í‰ê· ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    """,
    criteria=[
        "íƒ€ê²Ÿ ì í•©ì„±",
        "ë©”ì‹œì§€ ì „ë‹¬ë ¥",
        "ì°½ì˜ì„±",
        "ë¸Œëœë“œ ì í•©ì„±"
    ]
)

# Initialize session state
if 'scoring_config' not in st.session_state:
    st.session_state.scoring_config = DEFAULT_SCORING_CONFIG
if 'evaluator' not in st.session_state:
    st.session_state.evaluator = AdCopyEvaluator(st.session_state.scoring_config)
if 'history' not in st.session_state:
    st.session_state.history = []


# Sidebar configuration
with st.sidebar:
    st.header("âš™ï¸ í‰ê°€ ì‹œìŠ¤í…œ ì„¤ì •")
    
    with st.expander("í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
        new_prompt = st.text_area(
            "í‰ê°€ í”„ë¡¬í”„íŠ¸",
            value=st.session_state.scoring_config.prompt
        )
        new_criteria = st.text_area(
            "í‰ê°€ ê¸°ì¤€ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
            value="\n".join(st.session_state.scoring_config.criteria)
        )
        
        if st.button("í‰ê°€ ì„¤ì • ì—…ë°ì´íŠ¸"):
            new_config = ScoringConfig(
                prompt=new_prompt,
                criteria=[c.strip() for c in new_criteria.split('\n') if c.strip()]
            )
            st.session_state.scoring_config = new_config
            st.session_state.evaluator = AdCopyEvaluator(new_config)
            st.success("í‰ê°€ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # Target selection
    st.header("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •")
    
    selected_region = st.selectbox(
        "ì§€ì—­ ì„ íƒ",
        options=[""] + list(DOCS["region"].keys()),
        format_func=lambda x: "ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”" if x == "" else x
    )
    
    selected_generation = st.selectbox(
        "ì„¸ëŒ€ ì„ íƒ",
        options=[""] + list(DOCS["generation"].keys()),
        format_func=lambda x: "ì„¸ëŒ€ë¥¼ ì„ íƒí•˜ì„¸ìš”" if x == "" else x
    )
    
    
    # MBTI ì„ íƒ UI ìˆ˜ì •
    include_mbti = st.checkbox("MBTI íŠ¹ì„± í¬í•¨í•˜ê¸°", value=False)
    selected_mbti = None
    
    if include_mbti:
        selected_mbti = st.selectbox(
            "MBTI ì„ íƒ",
            options=MBTI_TYPES,
            help="MBTI ìœ í˜•ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ ì„±í–¥ì— ë§ëŠ” ì¹´í”¼ê°€ ìƒì„±ë©ë‹ˆë‹¤"
        )
# Main content
col1, col2 = st.columns([3, 2])

with col1:
    st.subheader("ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì‘ì„±")
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = create_adaptive_prompt(
        city_doc=DOCS["region"].get(selected_region, "ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."),
        target_generation=selected_generation,
        mbti=selected_mbti,
        include_mbti=include_mbti
    )
    
    # í”„ë¡¬í”„íŠ¸ í‘œì‹œ ë° í¸ì§‘ ê°€ëŠ¥í•˜ê²Œ
    edited_prompt = st.text_area(
        "ìƒì„± í”„ë¡¬í”„íŠ¸",
        value=prompt,
        height=400
    )
    
    if st.button("ğŸ¨ ê´‘ê³  ì¹´í”¼ ìƒì„±", use_container_width=True):
        if not selected_region or not selected_generation:
            st.error("ì§€ì—­ê³¼ ì„¸ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("AI ëª¨ë¸ì´ ê´‘ê³  ì¹´í”¼ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                # Generate copies
                results = {
                    model: generate_copy(prompt, model)
                    for model in ["gpt", "gemini", "claude"]
                }
                
                # Evaluate copies
                evaluations = {
                    model: st.session_state.evaluator.evaluate(copy, model)
                    for model, copy in results.items()
                }
                
                # Save results
                experiment_data = {
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "prompt": prompt,
                    "results": results,
                    "evaluations": evaluations,
                    "settings": {
                        "region": selected_region,
                        "generation": selected_generation,
                        "mbti": selected_mbti
                    }
                }
                st.session_state.history.append(experiment_data)
with col2:
    st.subheader("ğŸ“Š ì‹¤í—˜ ê²°ê³¼")
    
    for idx, experiment in enumerate(reversed(st.session_state.history)):
        with st.container():
            st.markdown(f"""
            <div class="result-card">
                <p style='color: #64748b; font-size: 0.875rem;'>{experiment['timestamp']}</p>
                <div style='margin: 1rem 0;'>
            """, unsafe_allow_html=True)
            
            for model in ["gpt", "gemini", "claude"]:
                result = experiment['results'][model]
                evaluation = experiment['evaluations'][model]
                
                st.markdown(f"""
                <div style='margin-bottom: 1.5rem;'>
                    <span class="model-tag {model}-tag">{model.upper()}</span>
                    <div style='background-color: #f8fafc; padding: 1rem; border-radius: 8px; margin: 0.5rem 0;'>
                        {result}
                    </div>
                    <div class="evaluation-score">
                        ì ìˆ˜: {evaluation['score']}ì 
                    </div>
                    <div class="evaluation-reason">
                        {evaluation['reason']}
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                fig = visualize_evaluation_results(evaluation)
                st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("</div></div>", unsafe_allow_html=True)
